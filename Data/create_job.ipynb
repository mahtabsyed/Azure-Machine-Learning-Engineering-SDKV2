{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import command, Input\n",
    "from azure.ai.ml.entities import (\n",
    "    AzureBlobDatastore,\n",
    "    AzureFileDatastore,\n",
    "    AzureDataLakeGen1Datastore,\n",
    "    AzureDataLakeGen2Datastore,\n",
    ")\n",
    "from azure.ai.ml.entities import Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n",
    "ml_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materializing MLTable artifact into pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltable\n",
    "tbl = mltable.load(uri=\"./my_data\")\n",
    "df = tbl.to_pandas_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker environment created for consuming MLTable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "    conda_file=\"env-mltable.yml\",\n",
    "    name=\"mltable\",\n",
    "    description=\"Environment created for consuming MLTable.\",\n",
    ")\n",
    "\n",
    "ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a compute cluster where the AML job is submitted to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7f089aaf9060>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import ComputeInstance, AmlCompute\n",
    "\n",
    "compute_cluster = AmlCompute(\n",
    "    name=\"cpu-cluster\",\n",
    "    type=\"amlcompute\",\n",
    "    size=\"STANDARD_DS3_v2\",\n",
    "    location=\"australiaeast\",\n",
    "    min_instances=0,\n",
    "    max_instances=2,\n",
    "    idle_time_before_scale_down=120,\n",
    ")\n",
    "ml_client.begin_create_or_update(compute_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and submitting AML job\n",
    "for more information see https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-data-assets?tabs=Python-SDK#create-a-mltable-data-asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "\n",
    "# Possible Paths for Data:\n",
    "# Blob: https://<account_name>.blob.core.windows.net/<container_name>/<folder>/<file>\n",
    "# Datastore: azureml://datastores/paths/<folder>/<file>\n",
    "# Data Asset: azureml:<my_data>:<version>\n",
    "\n",
    "\n",
    "# for example you can use either one of the following paths:\n",
    "inputs = {\"input_data\": Input(type=AssetTypes.MLTABLE, path=\"./my_data/\")}\n",
    "# or\n",
    "# inputs = {\"input_data\": Input(type=AssetTypes.MLTABLE, path=\"azureml:titanic-mltable-sdk:2\")}\n",
    "\n",
    "job = command(\n",
    "    code=\".\",  # local path where the code is stored\n",
    "    command=\"python read_data.py --input_data ${{inputs.input_data}}\",\n",
    "    inputs=inputs,\n",
    "    environment=env_docker_conda,\n",
    "    compute=\"cpu-cluster\",\n",
    ")\n",
    "\n",
    "# submit the command\n",
    "returned_job = ml_client.jobs.create_or_update(job)\n",
    "# get a URL for the status of the job\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
